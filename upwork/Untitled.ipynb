{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a821f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter number of future time periods to predict :450\n",
      "Enter the frequency of your data. Example 1T for one munute, 10T for ten minutes 1D for daily ETC.:10T\n",
      "                        1\n",
      "0                        \n",
      "2021-03-27 05:50:00  14.0\n",
      "2021-03-27 06:00:00  14.0\n",
      "2021-03-27 06:10:00  12.0\n",
      "2021-03-27 06:20:00  22.0\n",
      "2021-03-27 06:30:00  29.0\n",
      "505\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "\n",
    "future_days = input(\"Please enter number of future time periods to predict :\")\n",
    "future_days = int(future_days)\n",
    "time_freq = input(\"Enter the frequency of your data. Example 1T for one munute, 10T for ten minutes 1D for daily ETC.:\")\n",
    "\n",
    "#Data import.\n",
    "#data = pd.read_csv(\"short.csv\",index_col='date', parse_dates=True)\n",
    "data = pd.read_csv(\"long_ascending.csv\", index_col=0, parse_dates=True, header=None)\n",
    "data = data.astype('float')\n",
    "print(data.head())\n",
    "datelist_train = list(data.index)\n",
    "print(len(data))\n",
    "#Scale data to a range of -1,1 and split to training and testing set.\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(data)\n",
    "dataset = scaler.transform(data)\n",
    "train_data = int(len(dataset) * 0.9)\n",
    "test_data = (int(len(dataset) - train_data ))\n",
    "train, test = dataset[0:train_data], dataset[train_data:len(dataset)]\n",
    "# Reshape data to lenght, timesteps and number of features.\n",
    "n_future = 1 \n",
    "n_past = 14 \n",
    "def create_dataset(my_data, n_future, n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(my_data) - n_future +1):\n",
    "        dataX.append(my_data[i - n_past:i, 0:my_data.shape[1]])\n",
    "        dataY.append(my_data[i + n_future - 1:i + n_future, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "trainX, trainY = create_dataset(train, n_future, n_past)\n",
    "testX, testY = create_dataset(test, n_future, n_past)\n",
    "print(len(trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe77620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
